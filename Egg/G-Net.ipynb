{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anggita.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR3EuvPAwB6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dcbfd58e-2681-4d87-e4a1-255c0512be32"
      },
      "source": [
        "#import libarries dan Bikin Arsitektur\n",
        "\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers import concatenate\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "class GoogLeNet:\n",
        "    @staticmethod\n",
        "    def conv_module(x, K, kX, kY, stride, chanDim,\n",
        "        padding = \"same\", reg = 0.0005, name = None):\n",
        "        # initialize the CONV, BN, and RELU layer names\n",
        "        (convName, bnName, actName) = (None, None, None)\n",
        "\n",
        "        # if a layer name was supplied, prepend it\n",
        "        if name is not None:\n",
        "            convName = name + \"_conv\"\n",
        "            bnName = name + \"_bn\"\n",
        "            actName = name + \"_act\"\n",
        "\n",
        "        # define a CONV => BN => RELU pattern\n",
        "        x = Conv2D(K, (kX, kY), strides = stride, padding = padding,\n",
        "            kernel_regularizer = l2(reg), name = convName)(x)\n",
        "        x = BatchNormalization(axis = chanDim, name = bnName)(x)\n",
        "        x = Activation(\"relu\", name = actName)(x)\n",
        "\n",
        "        # return the block\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def inception_module(x, num1x1, num3x3Reduce, num3x3, num5x5Reduce,\n",
        "        num5x5, num1x1Proj, chanDim, stage, reg = 0.0005):\n",
        "        # define the first branch of the Inception module which\n",
        "        # consists of 1x1 convolutions\n",
        "        first = GoogLeNet.conv_module(x, num1x1, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_first\")\n",
        "\n",
        "        # define the second branch of the Inception module which\n",
        "        # consists of 1x1 and 3x3 convolutions\n",
        "        second = GoogLeNet.conv_module(x, num3x3Reduce, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_second1\")\n",
        "        second = GoogLeNet.conv_module(second, num3x3, 3, 3, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_second2\")\n",
        "\n",
        "        # define the third branch of the Inception module which\n",
        "        # are both 1x1 and 5x5 convolutions\n",
        "        third = GoogLeNet.conv_module(x, num5x5Reduce, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_third1\")\n",
        "        third = GoogLeNet.conv_module(third, num5x5, 5, 5, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_third2\")\n",
        "\n",
        "        # define the fourth branch of the Inception module which\n",
        "        # is the POOL projection\n",
        "        fourth = MaxPooling2D((3, 3), strides = (1, 1), padding = \"same\",\n",
        "            name = stage + \"_pool\")(x)\n",
        "        fourth = GoogLeNet.conv_module(fourth, num1x1Proj, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_fourth\")\n",
        "\n",
        "        # concatenate across the channel dimension\n",
        "        x = concatenate([first, second, third, fourth], axis = chanDim,\n",
        "            name = stage + \"_mixed\")\n",
        "\n",
        "        # return the block\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes, reg = 0.0005):\n",
        "        # initialize the input shape to be \"channel last\" and the\n",
        "        # channels dimension itself\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "\n",
        "       # if we are using \"channel first\", update the input shape\n",
        "        # and channels dimension\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "            chanDim = 1\n",
        "\n",
        "        # define the model input, followed by a sequence of\n",
        "        # CONV => POOL => (CONV * 2) => POOL layers\n",
        "        inputs = Input(shape = inputShape)\n",
        "        x = GoogLeNet.conv_module(inputs, 64, 5, 5, (1, 1),\n",
        "            chanDim, reg = reg, name = \"block1\")\n",
        "        x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",\n",
        "            name = \"pool1\")(x)\n",
        "        x = GoogLeNet.conv_module(x, 64, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = \"block2\")\n",
        "        x = GoogLeNet.conv_module(x, 192, 3, 3, (1, 1),\n",
        "            chanDim, reg = reg, name = \"block3\")\n",
        "        x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",\n",
        "            name = \"pool2\")(x)\n",
        "\n",
        "        # apply two Inception module followed by a POOL\n",
        "        x = GoogLeNet.inception_module(x, 64, 96, 128, 16, 32, 32,\n",
        "            chanDim, \"3a\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 128, 128, 192, 32, 96, 64,\n",
        "            chanDim, \"3b\", reg = reg)\n",
        "        x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",\n",
        "            name = \"pool3\")(x)\n",
        "\n",
        "        # apply five Inception module followed by POOL\n",
        "        x = GoogLeNet.inception_module(x, 192, 96, 208, 16, 48, 64,\n",
        "            chanDim, \"4a\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 160, 112, 224, 24, 64, 64,\n",
        "            chanDim, \"4b\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 128, 128, 256, 24, 64, 64,\n",
        "            chanDim, \"4c\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 112, 144, 288, 32, 64, 64,\n",
        "            chanDim, \"4d\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 256, 160, 320, 32, 128, 128,\n",
        "            chanDim, \"4e\", reg = reg)\n",
        "        x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",\n",
        "            name = \"pool4\")(x)\n",
        "\n",
        "        # apply last two Inception module\n",
        "        x = GoogLeNet.inception_module(x, 256, 160, 320, 32, 128, 128,\n",
        "            chanDim, \"5a\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 384, 192, 384, 48, 128, 128,\n",
        "            chanDim, \"5b\", reg = reg)\n",
        "\n",
        "        # apply a POOL layer (average) followed by dropout\n",
        "        x = AveragePooling2D((4, 4), name = \"pool5\")(x)\n",
        "        x = Dropout(0.4, name = \"do\")(x)\n",
        "\n",
        "        # softmax classifier\n",
        "        x = Flatten(name = \"flatten\")(x)\n",
        "        #x = layers.Dropout(0.5)(x)\n",
        "        x = Dense(classes, kernel_regularizer = l2(reg), name = \"labels\")(x)\n",
        "        x = Activation(\"softmax\", name = \"softmax\")(x)\n",
        "\n",
        "        # create the model\n",
        "        model = Model(inputs, x, name = \"googlenet\")\n",
        "\n",
        "        # return the constructed network architecture\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Q9hjhrwJnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "52b21a22-1013-42c4-cd3f-44c422ccfd5e"
      },
      "source": [
        "#link ke google drive\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "#### Updated ####\n",
        "\n",
        "#### Updated ####\n",
        "### The following two lines caused the issue:\n",
        "import sys\n",
        "#sys.path.append('/content/gdrive/My Drive/ColabNotebooks')\n",
        "sys.path.append('/content/gdrive/My Drive')\n",
        "\n",
        "### Replacing the above with these two lines solved the issue:\n",
        "import os\n",
        "#os.chdir('/content/gdrive/My Drive/ColabNotebooks') # Ch working directory to project folder\n",
        "os.chdir('/content/gdrive/My Drive') # Ch working directory to project folder\n",
        "\n",
        "###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuupztKgwN_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90814e78-da05-43e9-d1c2-ca65aecbf73b"
      },
      "source": [
        "#setting path gambar di gdrive\n",
        "\n",
        "print(\"[INFO] loading images...\")\n",
        "#imagePaths = paths.list_images('DATA SET TA')\n",
        "imagePaths = paths.list_images('Dataset')\n",
        "\n",
        "#imagePaths = paths.list_images('Dataset150')\n",
        "\n",
        "data = []\n",
        "labels = []\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE7xUPEkxIRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93c77f18-3b0f-48bc-dc76-62060969d98d"
      },
      "source": [
        "#setting path gambar di gdrive\n",
        "\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePathV = paths.list_images('CEK/Validasi')\n",
        "imagePathD = paths.list_images('CEK/Dataset')\n",
        "\n",
        "#imagePaths = paths.list_images('Dataset150')\n",
        "\n",
        "data = []\n",
        "labelsd = []\n",
        "val = []\n",
        "labelsv = []\n",
        "aug = []\n",
        "labels2 = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7mQThotwWhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ambil dataset Asli tanpa augmen warna\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "\n",
        "  a = Image.open(imagePath)\n",
        "  image = np.array(a.resize((224,224))) / 255.0\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labelsd.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNMYbhDGxU7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #ambil dataset Asli tanpa augmen warna\n",
        "\n",
        "# for imagePath in imagePathD:\n",
        "\n",
        "#   a = Image.open(imagePath)\n",
        "#   image = np.array(a.resize((224,224))) / 255.0\n",
        "#   data.append(image)\n",
        "\n",
        "#   label = imagePath.split(os.path.sep) [-2]\n",
        "#   labelsd.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jREz1P0xWa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ambil dataset Asli tanpa augmen warna\n",
        "\n",
        "for imagePath in imagePathV:\n",
        "\n",
        "  a = Image.open(imagePath)\n",
        "  image = np.array(a.resize((224,224))) / 255.0\n",
        "  val.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labelsv.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJcLjoefwYri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function buat Augmentasi\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=125,\n",
        "      width_shift_range=0.7,\n",
        "      height_shift_range=0.7,\n",
        "      shear_range=0.7,\n",
        "      zoom_range=0.7,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XT8B0aWwcdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#masukin gambar warna dengan augmentasi dan asli \n",
        "\n",
        "for imagePath in imagePathD:\n",
        "\n",
        "  a = Image.open(imagePath)\n",
        "  image = np.array(a.resize((224,224))) / 255.0\n",
        "  x = image\n",
        "\n",
        "\n",
        "  aug.append(x)\n",
        "  x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "  \n",
        "  i = 0\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labels2.append(label)\n",
        "  for batch in datagen.flow(x, batch_size=1):\n",
        "    mas = x[0,:,:,:] #( 150, 150, 3)\n",
        "    aug.append(mas)\n",
        "    label = imagePath.split(os.path.sep) [-2]\n",
        "    labels2.append(label)\n",
        "    i += 1\n",
        "    if i % 3 == 0:\n",
        "      break \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAC_u7V9J1dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#masukin gambar warna dengan augmentasi dan asli \n",
        "\n",
        "for imagePath in imagePaths:\n",
        "\n",
        "  a = Image.open(imagePath)\n",
        "  image = np.array(a.resize((224,224))) / 255.0\n",
        "  x = image\n",
        "\n",
        "  data.append(x)\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labels.append(label)\n",
        "\n",
        "  aug.append(x)\n",
        "  x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "  \n",
        "  i = 0\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labels2.append(label)\n",
        "  for batch in datagen.flow(x, batch_size=1):\n",
        "    mas = x[0,:,:,:] #( 150, 150, 3)\n",
        "    aug.append(mas)\n",
        "    label = imagePath.split(os.path.sep) [-2]\n",
        "    labels2.append(label)\n",
        "    i += 1\n",
        "    if i % 3 == 0:\n",
        "      break \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUpycrHswk8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "4598499e-54f7-40c9-f183-33436f1ae788"
      },
      "source": [
        "#ini one hot encoding dataset tanpa augmentasi, \n",
        "  print(labels)\n",
        "  lb = LabelBinarizer()\n",
        "  labels = lb.fit_transform(labels)\n",
        "  #print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-f35d5394f246>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print(labels)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UowENR8CzgEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ini one hot encoding dataset tanpa augmentasi, \n",
        "print(labelsv)\n",
        "lb = LabelBinarizer()\n",
        "labelsv = lb.fit_transform(labelsv)\n",
        "print(labelsv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAx8vl4hx0Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ini one hot encoding dataset tanpa augmentasi, \n",
        "print(labels2)\n",
        "lb = LabelBinarizer()\n",
        "labels2 = lb.fit_transform(labels2)\n",
        "print(labels2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGym9TRFwpFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ini set data Train dan Test kalau pakai dataset asli aja\n",
        "(trainX,testX, trainY, testY) = train_test_split(np.array(data),\n",
        "np.array(labels), test_size=0.2)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "#kalau pakai ini yg bawah gak usah di run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgZm5kl_wrv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ini set data Train kalau pake augmen\n",
        "\n",
        "(trainX,dumbx, trainY, dumby) = train_test_split(np.array(aug),\n",
        "np.array(labels2),test_size=0.05)\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlVw_D2SwvmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ini set data Test kalau pake augmen\n",
        "#ini dan cell atas harus di run\n",
        "\n",
        "(dumbx,testX, dumby, testY) = train_test_split(np.array(val),\n",
        "np.array(labelsv), test_size=70)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZaV2nwDwyjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting arsi dan opt\n",
        "model = GoogLeNet.build(width = 224, height = 224, depth = 3,\n",
        "        classes = 4, reg = 0.0002)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5sxcdAHD8IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opt = SGD(lr = 1e-3)\n",
        "opt = Adam(lr = 1e-3)\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BjSMMB4d14G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compile?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK7_8_5iw084",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cek arsi\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWxRWPMOw4w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "#model = DecisionTreeClassifier()\n",
        "#running\n",
        "e = 55\n",
        "b = 32\n",
        "\n",
        "H=model.fit(trainX, trainY,validation_data=(testX, testY), batch_size=b, epochs=e, shuffle=True )\n",
        "predY=model.predict(testX)\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "model.evaluate(x=testX, y=testY, batch_size=32)\n",
        "list_of_metrics_to_plot = ['accuracy']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHiS8jKIw8V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluasi\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anB2_FBhw-X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluasi 2\n",
        "test_score = model.evaluate(testX, testY, batch_size = 32)\n",
        "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmZc2H2T-qdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJjIakMFxG6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bikin grafik epoch sama Val_acc\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "epochs = H.epoch\n",
        "hist = pd.DataFrame(H.history)\n",
        "list_of_metrics_to_plot = ['val_acc']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bcNB_F2xI3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#grafik val_acc sama train_acc\n",
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots()\n",
        "ax.plot([None] + H.history['accuracy'], 'o-')\n",
        "ax.plot([None] + H.history['val_accuracy'], 'x-')\n",
        "# Plot legend and use the best location automatically: loc = 0.\n",
        "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
        "ax.set_title('Training/Validation acc per Epoch')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxBi3SCDxLI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#grafik loss train dengan loss val\n",
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots()\n",
        "ax.plot([None] + H.history['loss'], 'o-')\n",
        "ax.plot([None] + H.history['val_loss'], 'x-')\n",
        "# Plot legend and use the best location automatically: loc = 0.\n",
        "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
        "ax.set_title('Training/Validation Loss per Epoch')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbv17afd_vzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h6R02mUxq5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bikin Confusion\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels=[\"Grade AA\", \"Grade A\", \"Grade B\",\"Grade C\"]\n",
        "print(confusion_matrix(testY, predY))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSHGhnCvxx2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run \n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "cm=multilabel_confusion_matrix(testY,predY)\n",
        "print(cm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dur5XxFZx0Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "predY[1]\n",
        "rounded_labels=np.argmax(predY, axis=1)\n",
        "rounded_labels[1]\n",
        "rounded_predict=np.argmax(testY, axis=1)\n",
        "rounded_predict[1]\n",
        "print(confusion_matrix(rounded_labels, rounded_predict))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPj3dkRpx2Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run\n",
        "rounded_labels[:,]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR50OkJ8x4lL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names=['1', '2', '3', '4'],\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    if normalize:\n",
        "      plt.imshow(cm/7, interpolation='nearest', cmap=cmap)\n",
        "    else:\n",
        "      plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.3f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkTAM5bhx9vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run\n",
        "#gambar confusion matrix\n",
        "cm = confusion_matrix(rounded_labels,  rounded_predict)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpRwH7kp2I9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_module(x, K, kX, kY, stride, chanDim,\n",
        "        padding = \"same\", reg = 0.0005, name = None):\n",
        "        # initialize the CONV, BN, and RELU layer names\n",
        "        (convName, bnName, actName) = (None, None, None)\n",
        "\n",
        "        # if a layer name was supplied, prepend it\n",
        "        if name is not None:\n",
        "            convName = name + \"_conv\"\n",
        "            bnName = name + \"_bn\"\n",
        "            actName = name + \"_act\"\n",
        "\n",
        "        # define a CONV => BN => RELU pattern\n",
        "        x = Conv2D(K, (kX, kY), strides = stride, padding = padding,\n",
        "            kernel_regularizer = l2(reg), name = convName)(x)\n",
        "        x = BatchNormalization(axis = chanDim, name = bnName)(x)\n",
        "        x = Activation(\"relu\", name = actName)(x)\n",
        "\n",
        "        # return the block\n",
        "        return x\n",
        "\n",
        "def inception_module(x, num1x1, num3x3Reduce, num3x3, num5x5Reduce,\n",
        "        num5x5, num1x1Proj, chanDim, stage, reg = 0.0005):\n",
        "        # define the first branch of the Inception module which\n",
        "        # consists of 1x1 convolutions\n",
        "        first = GoogLeNet.conv_module(x, num1x1, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_first\")\n",
        "\n",
        "        # define the second branch of the Inception module which\n",
        "        # consists of 1x1 and 3x3 convolutions\n",
        "        second = GoogLeNet.conv_module(x, num3x3Reduce, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_second1\")\n",
        "        second = GoogLeNet.conv_module(second, num3x3, 3, 3, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_second2\")\n",
        "\n",
        "        # define the third branch of the Inception module which\n",
        "        # are both 1x1 and 5x5 convolutions\n",
        "        third = GoogLeNet.conv_module(x, num5x5Reduce, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_third1\")\n",
        "        third = GoogLeNet.conv_module(third, num5x5, 5, 5, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_third2\")\n",
        "\n",
        "        # define the fourth branch of the Inception module which\n",
        "        # is the POOL projection\n",
        "        fourth = MaxPooling2D((3, 3), strides = (1, 1), padding = \"same\",\n",
        "            name = stage + \"_pool\")(x)\n",
        "        fourth = GoogLeNet.conv_module(fourth, num1x1Proj, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_fourth\")\n",
        "\n",
        "        # concatenate across the channel dimension\n",
        "        x = concatenate([first, second, third, fourth], axis = chanDim,\n",
        "            name = stage + \"_mixed\")\n",
        "\n",
        "        # return the block\n",
        "        return x\n",
        "\n",
        "width = 224\n",
        "height = 224\n",
        "depth = 3\n",
        "classes = 11\n",
        "reg = 0.0005\n",
        "chanDim = -1\n",
        "\n",
        "        # if we are using \"channel first\", update the input shape\n",
        "        # and channels dimension\n",
        "\n",
        "\n",
        "        # define the model input, followed by a sequence of\n",
        "        # CONV => POOL => (CONV * 2) => POOL layers\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "x = conv_module(inputs, 64, 5, 5, (1, 1), chanDim, reg = reg, name = \"block1\")\n",
        "x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\", name = \"pool1\")(x)\n",
        "x = conv_module(x, 64, 1, 1, (1, 1), chanDim, reg = reg, name = \"block2\")\n",
        "x = conv_module(x, 192, 3, 3, (1, 1), chanDim, reg = reg, name = \"block3\")\n",
        "x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",name = \"pool2\")(x)\n",
        "\n",
        "        # apply two Inception module followed by a POOL\n",
        "x = inception_module(x, 64, 96, 128, 16, 32, 32, chanDim, \"3a\", reg = reg)\n",
        "x = inception_module(x, 128, 128, 192, 32, 96, 64, chanDim, \"3b\", reg = reg)\n",
        "x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\", name = \"pool3\")(x)\n",
        "\n",
        "        # apply five Inception module followed by POOL\n",
        "x = inception_module(x, 192, 96, 208, 16, 48, 64, chanDim, \"4a\", reg = reg)\n",
        "x = inception_module(x, 160, 112, 224, 24, 64, 64, chanDim, \"4b\", reg = reg)\n",
        "x = inception_module(x, 128, 128, 256, 24, 64, 64, chanDim, \"4c\", reg = reg)\n",
        "x = inception_module(x, 112, 144, 288, 32, 64, 64, chanDim, \"4d\", reg = reg)\n",
        "x = inception_module(x, 256, 160, 320, 32, 128, 128, chanDim, \"4e\", reg = reg)\n",
        "x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\", name = \"pool4\")(x)\n",
        "\n",
        "        # apply last two Inception module\n",
        "x = inception_module(x, 256, 160, 320, 32, 128, 128, chanDim, \"5a\", reg = reg)\n",
        "x = inception_module(x, 384, 192, 384, 48, 128, 128, chanDim, \"5b\", reg = reg)\n",
        "\n",
        "        # apply a POOL layer (average) followed by dropout\n",
        "x = AveragePooling2D((4, 4), name = \"pool5\")(x)\n",
        "x = Dropout(0.4, name = \"do\")(x)\n",
        "\n",
        "        # softmax classifier\n",
        "x = Flatten(name = \"flatten\")(x)\n",
        "        #x = layers.Dropout(0.5)(x)\n",
        "x = Dense(classes, kernel_regularizer = l2(reg), name = \"labels\")(x)\n",
        "x = Activation(\"softmax\", name = \"softmax\")(x)\n",
        "\n",
        "        # create the model\n",
        "model = Model(inputs, x, name = \"googlenet\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKmyXgerB78k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGr97EKeyDNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "#inputs = Input(shape=(224, 224, 3))\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "visualization_model = Model(inputs, successive_outputs, name = \"googlenet\")\n",
        "\n",
        "img = load_img('Dataset/Grade A/IMG_0572.JPG', target_size=(224, 224))\n",
        "\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Postprocess the feature to make it visually palatable\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2vw3HRxAiJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ini cuma buat ngetes\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "\n",
        "gambarcek = os.listdir('Dataset/Grade A')\n",
        "img_path = os.path.join('Dataset/Grade A', gambarcek[2])\n",
        "img = load_img(img_path, target_size=(224, 224))  # this is a PIL image\n",
        "x = np.array(img) \n",
        "# Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# The .flow() command below generates batches of randomly transformed images\n",
        "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "  plt.figure(i)\n",
        "  imgplot = plt.imshow(array_to_img(batch[0]))\n",
        "  i += 1\n",
        "  if i % 5 == 0:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}