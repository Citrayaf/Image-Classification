{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nurul.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKLWS_d8zmHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "269ca047-d765-4ce5-e77d-05d1cbb335da"
      },
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "\n",
        "import pydot\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "#### Updated ####\n",
        "\n",
        "#### Updated ####\n",
        "### The following two lines caused the issue:\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "### Replacing the above with these two lines solved the issue:\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive') # Ch working directory to project folder\n",
        "###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJutHXMiz5ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d52a4f8-a855-4535-f1cf-0673545f0a01"
      },
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = paths.list_images('Dataset')\n",
        "data = []\n",
        "labels = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHU1olvqDHCh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16b9125f-7945-4fdc-a12f-e5f0b325c72e"
      },
      "source": [
        "#setting path gambar di gdrive\n",
        "\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePathV = paths.list_images('CEK/Validasi')\n",
        "imagePathD = paths.list_images('CEK/Dataset')\n",
        "\n",
        "#imagePaths = paths.list_images('Dataset150')\n",
        "\n",
        "data = []\n",
        "labelsd = []\n",
        "val = []\n",
        "labelsv = []\n",
        "aug = []\n",
        "labels2 = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AADUyLpDz9Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for imagePath in imagePaths:\n",
        "\n",
        "  image = Image.open(imagePath).convert('L')\n",
        "\n",
        "  image = np.array(image.resize((32,32))) / 255.0\n",
        "\n",
        "  image = np.expand_dims(image, axis=-1)\n",
        "\n",
        "\n",
        "  data.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labelsd.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FtxKkibDF0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ambil dataset Asli tanpa augmen warna\n",
        "\n",
        "for imagePath in imagePathV:\n",
        "\n",
        "  a = Image.open(imagePath).convert('L')\n",
        "  image = np.array(a.resize((32,32))) / 255.0\n",
        "  image = np.expand_dims(image, axis=-1)\n",
        "\n",
        "  val.append(image)\n",
        "\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labelsv.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7ArNWeFDWZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function buat Augmentasi\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=105,\n",
        "      width_shift_range=0.5,\n",
        "      height_shift_range=0.5,\n",
        "      shear_range=0.5,\n",
        "      zoom_range=0.5,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iSuBq1VDbQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#masukin gambar warna dengan augmentasi dan asli \n",
        "\n",
        "for imagePath in imagePathD:\n",
        "\n",
        "  a = Image.open(imagePath).convert('L')\n",
        "  image = np.array(a.resize((32,32))) / 255.0\n",
        "  image = np.expand_dims(image, axis=-1)\n",
        "\n",
        "  x = image\n",
        "\n",
        "\n",
        "  aug.append(x)\n",
        "  x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "  \n",
        "  i = 0\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labels2.append(label)\n",
        "  for batch in datagen.flow(x, batch_size=1):\n",
        "    mas = x[0,:,:,:] #( 150, 150, 3)\n",
        "    aug.append(mas)\n",
        "    label = imagePath.split(os.path.sep) [-2]\n",
        "    labels2.append(label)\n",
        "    i += 1\n",
        "    if i % 3 == 0:\n",
        "      break \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb-lLSmvD0SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#membuat dan memasukkan gambar gray pake CLAHE dengan augmentasi dan asli\n",
        "#note: pilih salah satu warna apa gray\n",
        "\n",
        "\n",
        "import cv2\n",
        "\n",
        "for imagePath in imagePathD:\n",
        "\n",
        "\n",
        "  a = Image.open(imagePath)\n",
        "\n",
        "  a = a.convert('L')\n",
        "\n",
        "\n",
        "  image = np.array(a.resize((32,32))) \n",
        "\n",
        "  clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
        "\n",
        "  image = clahe.apply(image)\n",
        "\n",
        "  image = image / 255.0\n",
        "  \n",
        "  image = np.expand_dims(image, axis=-1)\n",
        "\n",
        "\n",
        "  x = image\n",
        "\n",
        "\n",
        "  aug.append(x)\n",
        "  x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "  \n",
        "  i = 0\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labels2.append(label)\n",
        "  for batch in datagen.flow(x, batch_size=1):\n",
        "    mas = x[0,:,:,:] #( 150, 150, 3)\n",
        "    aug.append(mas)\n",
        "    label = imagePath.split(os.path.sep) [-2]\n",
        "    labels2.append(label)\n",
        "    i += 1\n",
        "    if i % 3 == 0:\n",
        "      break \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDmXZStoKgN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#masukin gambar warna dengan augmentasi dan asli \n",
        "\n",
        "for imagePath in imagePaths:\n",
        "\n",
        "  a = Image.open(imagePath).convert('L')\n",
        "  image = np.array(a.resize((32,32))) / 255.0\n",
        "  image = np.expand_dims(image, axis=-1)\n",
        "\n",
        "  x = image\n",
        "  data.append(x)\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labels.append(label)\n",
        "\n",
        "  aug.append(x)\n",
        "  x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "  \n",
        "  i = 0\n",
        "  label = imagePath.split(os.path.sep) [-2]\n",
        "  labels2.append(label)\n",
        "  for batch in datagen.flow(x, batch_size=1):\n",
        "    mas = x[0,:,:,:] #( 150, 150, 3)\n",
        "    aug.append(mas)\n",
        "    label = imagePath.split(os.path.sep) [-2]\n",
        "    labels2.append(label)\n",
        "    i += 1\n",
        "    if i % 3 == 0:\n",
        "      break \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPUc7pMi0BG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "90bd1c59-c0cd-49d9-8f9d-620d6d4309e1"
      },
      "source": [
        "print(labels)\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade AA ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade C ', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A']\n",
            "[[0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " ...\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJODSuoUEKEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e9c362e-cb28-4ffa-8b68-4abfa50a2746"
      },
      "source": [
        "#ini one hot encoding dataset tanpa augmentasi, \n",
        "print(labelsv)\n",
        "lb = LabelBinarizer()\n",
        "labelsv = lb.fit_transform(labelsv)\n",
        "print(labelsv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade AA', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade A', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade B', 'Grade C', 'Grade C', 'Grade C', 'Grade C', 'Grade C', 'Grade C', 'Grade C', 'Grade C', 'Grade C', 'Grade C']\n",
            "[[0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOnHGEBtEO4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9b731e1f-11c1-41e0-8ca5-b183933a9c8f"
      },
      "source": [
        "#ini one hot encoding dataset tanpa augmentasi, \n",
        "print(labels2)\n",
        "lb = LabelBinarizer()\n",
        "labels2 = lb.fit_transform(labels2)\n",
        "print(labels2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " ...\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]]\n",
            "[[0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " ...\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsQZliXO0DQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "619664b0-0664-4837-f33d-b9bf6ee4d41b"
      },
      "source": [
        "(trainX,testX, trainY, testY) = train_test_split(np.array(data),np.array(labels), test_size=0.20)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "trainY.shape\n",
        "print(trainY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(758, 32, 32, 1)\n",
            "(190, 32, 32, 1)\n",
            "[[0 1 0 0]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " ...\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuCtYAPAEWc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a050545-3647-4f56-cd16-2310910fe73f"
      },
      "source": [
        "#ini set data Train kalau pake augmen\n",
        "\n",
        "(trainX,dumbx, trainY, dumby) = train_test_split(np.array(aug),\n",
        "np.array(labels2),test_size=0.05)\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3328, 32, 32, 1)\n",
            "(3328, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk2xmtg_EZzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a9d81321-5b42-4ef8-b320-aee2232dc122"
      },
      "source": [
        "#ini set data Test kalau pake augmen\n",
        "#ini dan cell atas harus di run\n",
        "\n",
        "(dumbx,testX, dumby, testY) = train_test_split(np.array(val),\n",
        "np.array(labelsv), test_size=70)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70, 32, 32, 1)\n",
            "(70, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9DcwcuE0LPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import models, layers\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "\n",
        "import keras\n",
        "#Instantiate an empty model\n",
        "model = Sequential()\n",
        "\n",
        "# C1 Convolutional Layer\n",
        "model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(32,32,1), padding=\"same\"))\n",
        "\n",
        "# S2 Pooling Layer\n",
        "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
        "\n",
        "# C3 Convolutional Layer8\n",
        "model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
        "\n",
        "# S4 Pooling Layer\n",
        "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "# C5 Fully Connected Convolutional Layer\n",
        "model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
        "#Flatten the CNN output so that we can connect it with fully connected layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# FC6 Fully Connected Layer\n",
        "model.add(layers.Dense(84, activation='tanh'))\n",
        "\n",
        "#Output Layer with softmax activation\n",
        "model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "opt = SGD(lr = 1e-3)\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPPh8kic0kAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "3b35f995-ae93-4ab1-839d-6f15ffb23f95"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_5 (Average (None, 31, 31, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 27, 27, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 9, 9, 120)         48120     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 9720)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 84)                816564    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4)                 340       \n",
            "=================================================================\n",
            "Total params: 867,596\n",
            "Trainable params: 867,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNz7Tvzf0QxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0376615-55e0-49f6-d4b6-5ca7c9d4df7d"
      },
      "source": [
        "H = model.fit(x=trainX,y=trainY, epochs=50, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
        "predY=model.predict(testX)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3328 samples, validate on 70 samples\n",
            "Epoch 1/50\n",
            "3328/3328 [==============================] - 1s 163us/step - loss: 1.3359 - accuracy: 0.3305 - val_loss: 1.3505 - val_accuracy: 0.3000\n",
            "Epoch 2/50\n",
            "3328/3328 [==============================] - 0s 126us/step - loss: 1.3296 - accuracy: 0.3299 - val_loss: 1.3477 - val_accuracy: 0.3286\n",
            "Epoch 3/50\n",
            "3328/3328 [==============================] - 0s 129us/step - loss: 1.3295 - accuracy: 0.3284 - val_loss: 1.3473 - val_accuracy: 0.3000\n",
            "Epoch 4/50\n",
            "3328/3328 [==============================] - 0s 125us/step - loss: 1.3268 - accuracy: 0.3302 - val_loss: 1.3502 - val_accuracy: 0.3000\n",
            "Epoch 5/50\n",
            "3328/3328 [==============================] - 0s 115us/step - loss: 1.3257 - accuracy: 0.3263 - val_loss: 1.3453 - val_accuracy: 0.3000\n",
            "Epoch 6/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.3240 - accuracy: 0.3329 - val_loss: 1.3498 - val_accuracy: 0.3000\n",
            "Epoch 7/50\n",
            "3328/3328 [==============================] - 0s 118us/step - loss: 1.3228 - accuracy: 0.3299 - val_loss: 1.3442 - val_accuracy: 0.3857\n",
            "Epoch 8/50\n",
            "3328/3328 [==============================] - 0s 113us/step - loss: 1.3216 - accuracy: 0.3341 - val_loss: 1.3439 - val_accuracy: 0.3286\n",
            "Epoch 9/50\n",
            "3328/3328 [==============================] - 0s 119us/step - loss: 1.3192 - accuracy: 0.3462 - val_loss: 1.3436 - val_accuracy: 0.3000\n",
            "Epoch 10/50\n",
            "3328/3328 [==============================] - 0s 124us/step - loss: 1.3176 - accuracy: 0.3507 - val_loss: 1.3462 - val_accuracy: 0.2857\n",
            "Epoch 11/50\n",
            "3328/3328 [==============================] - 0s 125us/step - loss: 1.3164 - accuracy: 0.3528 - val_loss: 1.3404 - val_accuracy: 0.3571\n",
            "Epoch 12/50\n",
            "3328/3328 [==============================] - 0s 125us/step - loss: 1.3151 - accuracy: 0.3513 - val_loss: 1.3465 - val_accuracy: 0.3000\n",
            "Epoch 13/50\n",
            "3328/3328 [==============================] - 0s 117us/step - loss: 1.3139 - accuracy: 0.3498 - val_loss: 1.3460 - val_accuracy: 0.2857\n",
            "Epoch 14/50\n",
            "3328/3328 [==============================] - 0s 119us/step - loss: 1.3125 - accuracy: 0.3591 - val_loss: 1.3445 - val_accuracy: 0.3000\n",
            "Epoch 15/50\n",
            "3328/3328 [==============================] - 0s 120us/step - loss: 1.3105 - accuracy: 0.3594 - val_loss: 1.3445 - val_accuracy: 0.2714\n",
            "Epoch 16/50\n",
            "3328/3328 [==============================] - 0s 125us/step - loss: 1.3096 - accuracy: 0.3570 - val_loss: 1.3443 - val_accuracy: 0.3000\n",
            "Epoch 17/50\n",
            "3328/3328 [==============================] - 0s 124us/step - loss: 1.3073 - accuracy: 0.3687 - val_loss: 1.3457 - val_accuracy: 0.3143\n",
            "Epoch 18/50\n",
            "3328/3328 [==============================] - 0s 122us/step - loss: 1.3063 - accuracy: 0.3714 - val_loss: 1.3451 - val_accuracy: 0.2571\n",
            "Epoch 19/50\n",
            "3328/3328 [==============================] - 0s 122us/step - loss: 1.3049 - accuracy: 0.3696 - val_loss: 1.3439 - val_accuracy: 0.3429\n",
            "Epoch 20/50\n",
            "3328/3328 [==============================] - 0s 117us/step - loss: 1.3029 - accuracy: 0.3720 - val_loss: 1.3427 - val_accuracy: 0.3429\n",
            "Epoch 21/50\n",
            "3328/3328 [==============================] - 0s 123us/step - loss: 1.3017 - accuracy: 0.3774 - val_loss: 1.3507 - val_accuracy: 0.2714\n",
            "Epoch 22/50\n",
            "3328/3328 [==============================] - 0s 130us/step - loss: 1.2995 - accuracy: 0.3762 - val_loss: 1.3503 - val_accuracy: 0.3143\n",
            "Epoch 23/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.2974 - accuracy: 0.3792 - val_loss: 1.3517 - val_accuracy: 0.2857\n",
            "Epoch 24/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.2960 - accuracy: 0.3816 - val_loss: 1.3440 - val_accuracy: 0.3286\n",
            "Epoch 25/50\n",
            "3328/3328 [==============================] - 0s 115us/step - loss: 1.2948 - accuracy: 0.3894 - val_loss: 1.3521 - val_accuracy: 0.2571\n",
            "Epoch 26/50\n",
            "3328/3328 [==============================] - 0s 123us/step - loss: 1.2920 - accuracy: 0.3915 - val_loss: 1.3583 - val_accuracy: 0.2714\n",
            "Epoch 27/50\n",
            "3328/3328 [==============================] - 0s 119us/step - loss: 1.2915 - accuracy: 0.3852 - val_loss: 1.3457 - val_accuracy: 0.3286\n",
            "Epoch 28/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.2888 - accuracy: 0.3924 - val_loss: 1.3551 - val_accuracy: 0.2857\n",
            "Epoch 29/50\n",
            "3328/3328 [==============================] - 0s 109us/step - loss: 1.2886 - accuracy: 0.3861 - val_loss: 1.3479 - val_accuracy: 0.3286\n",
            "Epoch 30/50\n",
            "3328/3328 [==============================] - 0s 111us/step - loss: 1.2865 - accuracy: 0.3894 - val_loss: 1.3449 - val_accuracy: 0.3143\n",
            "Epoch 31/50\n",
            "3328/3328 [==============================] - 0s 110us/step - loss: 1.2850 - accuracy: 0.3879 - val_loss: 1.3502 - val_accuracy: 0.3000\n",
            "Epoch 32/50\n",
            "3328/3328 [==============================] - 0s 117us/step - loss: 1.2832 - accuracy: 0.3924 - val_loss: 1.3526 - val_accuracy: 0.3000\n",
            "Epoch 33/50\n",
            "3328/3328 [==============================] - 0s 117us/step - loss: 1.2811 - accuracy: 0.3915 - val_loss: 1.3568 - val_accuracy: 0.3000\n",
            "Epoch 34/50\n",
            "3328/3328 [==============================] - 0s 122us/step - loss: 1.2796 - accuracy: 0.3873 - val_loss: 1.3656 - val_accuracy: 0.2429\n",
            "Epoch 35/50\n",
            "3328/3328 [==============================] - 0s 117us/step - loss: 1.2776 - accuracy: 0.3945 - val_loss: 1.3544 - val_accuracy: 0.3000\n",
            "Epoch 36/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.2766 - accuracy: 0.3987 - val_loss: 1.3533 - val_accuracy: 0.3429\n",
            "Epoch 37/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.2743 - accuracy: 0.3963 - val_loss: 1.3664 - val_accuracy: 0.3286\n",
            "Epoch 38/50\n",
            "3328/3328 [==============================] - 0s 117us/step - loss: 1.2734 - accuracy: 0.3954 - val_loss: 1.3506 - val_accuracy: 0.3429\n",
            "Epoch 39/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.2716 - accuracy: 0.3969 - val_loss: 1.3684 - val_accuracy: 0.3000\n",
            "Epoch 40/50\n",
            "3328/3328 [==============================] - 0s 115us/step - loss: 1.2701 - accuracy: 0.4023 - val_loss: 1.3680 - val_accuracy: 0.3143\n",
            "Epoch 41/50\n",
            "3328/3328 [==============================] - 0s 120us/step - loss: 1.2693 - accuracy: 0.3918 - val_loss: 1.3740 - val_accuracy: 0.3000\n",
            "Epoch 42/50\n",
            "3328/3328 [==============================] - 0s 118us/step - loss: 1.2677 - accuracy: 0.3954 - val_loss: 1.3721 - val_accuracy: 0.3000\n",
            "Epoch 43/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.2649 - accuracy: 0.4011 - val_loss: 1.3604 - val_accuracy: 0.3000\n",
            "Epoch 44/50\n",
            "3328/3328 [==============================] - 0s 115us/step - loss: 1.2640 - accuracy: 0.3945 - val_loss: 1.3628 - val_accuracy: 0.3000\n",
            "Epoch 45/50\n",
            "3328/3328 [==============================] - 0s 122us/step - loss: 1.2617 - accuracy: 0.4026 - val_loss: 1.3844 - val_accuracy: 0.3000\n",
            "Epoch 46/50\n",
            "3328/3328 [==============================] - 0s 118us/step - loss: 1.2605 - accuracy: 0.4047 - val_loss: 1.3884 - val_accuracy: 0.2714\n",
            "Epoch 47/50\n",
            "3328/3328 [==============================] - 0s 116us/step - loss: 1.2592 - accuracy: 0.4059 - val_loss: 1.3821 - val_accuracy: 0.3143\n",
            "Epoch 48/50\n",
            "3328/3328 [==============================] - 0s 124us/step - loss: 1.2585 - accuracy: 0.3987 - val_loss: 1.3823 - val_accuracy: 0.2714\n",
            "Epoch 49/50\n",
            "3328/3328 [==============================] - 0s 119us/step - loss: 1.2575 - accuracy: 0.4084 - val_loss: 1.3843 - val_accuracy: 0.2714\n",
            "Epoch 50/50\n",
            "3328/3328 [==============================] - 0s 119us/step - loss: 1.2558 - accuracy: 0.4069 - val_loss: 1.3878 - val_accuracy: 0.2714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTTVgEPxSEYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f3e8c9e-db32-4bf8-b252-a0922607c1ac"
      },
      "source": [
        "H = model.fit(x=trainX,y=trainY, epochs=50, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
        "predY=model.predict(testX)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 758 samples, validate on 190 samples\n",
            "Epoch 1/50\n",
            "758/758 [==============================] - 0s 322us/step - loss: 1.3239 - accuracy: 0.3430 - val_loss: 1.2922 - val_accuracy: 0.4053\n",
            "Epoch 2/50\n",
            "758/758 [==============================] - 0s 306us/step - loss: 1.3237 - accuracy: 0.3549 - val_loss: 1.2908 - val_accuracy: 0.3789\n",
            "Epoch 3/50\n",
            "758/758 [==============================] - 0s 297us/step - loss: 1.3227 - accuracy: 0.3536 - val_loss: 1.2946 - val_accuracy: 0.3842\n",
            "Epoch 4/50\n",
            "758/758 [==============================] - 0s 306us/step - loss: 1.3241 - accuracy: 0.3509 - val_loss: 1.2927 - val_accuracy: 0.3895\n",
            "Epoch 5/50\n",
            "758/758 [==============================] - 0s 305us/step - loss: 1.3230 - accuracy: 0.3628 - val_loss: 1.2882 - val_accuracy: 0.3842\n",
            "Epoch 6/50\n",
            "758/758 [==============================] - 0s 314us/step - loss: 1.3220 - accuracy: 0.3654 - val_loss: 1.2887 - val_accuracy: 0.3842\n",
            "Epoch 7/50\n",
            "758/758 [==============================] - 0s 305us/step - loss: 1.3215 - accuracy: 0.3509 - val_loss: 1.2916 - val_accuracy: 0.3684\n",
            "Epoch 8/50\n",
            "758/758 [==============================] - 0s 305us/step - loss: 1.3223 - accuracy: 0.3575 - val_loss: 1.2906 - val_accuracy: 0.3789\n",
            "Epoch 9/50\n",
            "758/758 [==============================] - 0s 311us/step - loss: 1.3202 - accuracy: 0.3536 - val_loss: 1.2926 - val_accuracy: 0.4053\n",
            "Epoch 10/50\n",
            "758/758 [==============================] - 0s 317us/step - loss: 1.3207 - accuracy: 0.3654 - val_loss: 1.2894 - val_accuracy: 0.3947\n",
            "Epoch 11/50\n",
            "758/758 [==============================] - 0s 301us/step - loss: 1.3214 - accuracy: 0.3588 - val_loss: 1.2892 - val_accuracy: 0.3895\n",
            "Epoch 12/50\n",
            "758/758 [==============================] - 0s 302us/step - loss: 1.3197 - accuracy: 0.3734 - val_loss: 1.2904 - val_accuracy: 0.3789\n",
            "Epoch 13/50\n",
            "758/758 [==============================] - 0s 307us/step - loss: 1.3190 - accuracy: 0.3549 - val_loss: 1.2906 - val_accuracy: 0.3947\n",
            "Epoch 14/50\n",
            "758/758 [==============================] - 0s 326us/step - loss: 1.3191 - accuracy: 0.3773 - val_loss: 1.2930 - val_accuracy: 0.3842\n",
            "Epoch 15/50\n",
            "758/758 [==============================] - 0s 301us/step - loss: 1.3186 - accuracy: 0.3694 - val_loss: 1.2874 - val_accuracy: 0.3895\n",
            "Epoch 16/50\n",
            "758/758 [==============================] - 0s 307us/step - loss: 1.3188 - accuracy: 0.3575 - val_loss: 1.2918 - val_accuracy: 0.3947\n",
            "Epoch 17/50\n",
            "758/758 [==============================] - 0s 303us/step - loss: 1.3183 - accuracy: 0.3628 - val_loss: 1.2879 - val_accuracy: 0.3895\n",
            "Epoch 18/50\n",
            "758/758 [==============================] - 0s 322us/step - loss: 1.3177 - accuracy: 0.3720 - val_loss: 1.2872 - val_accuracy: 0.3895\n",
            "Epoch 19/50\n",
            "758/758 [==============================] - 0s 316us/step - loss: 1.3170 - accuracy: 0.3707 - val_loss: 1.2897 - val_accuracy: 0.3895\n",
            "Epoch 20/50\n",
            "758/758 [==============================] - 0s 301us/step - loss: 1.3164 - accuracy: 0.3760 - val_loss: 1.2869 - val_accuracy: 0.3684\n",
            "Epoch 21/50\n",
            "758/758 [==============================] - 0s 303us/step - loss: 1.3165 - accuracy: 0.3641 - val_loss: 1.2841 - val_accuracy: 0.3842\n",
            "Epoch 22/50\n",
            "758/758 [==============================] - 0s 318us/step - loss: 1.3168 - accuracy: 0.3799 - val_loss: 1.2830 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "758/758 [==============================] - 0s 314us/step - loss: 1.3157 - accuracy: 0.3799 - val_loss: 1.2850 - val_accuracy: 0.3842\n",
            "Epoch 24/50\n",
            "758/758 [==============================] - 0s 313us/step - loss: 1.3160 - accuracy: 0.3588 - val_loss: 1.2888 - val_accuracy: 0.3842\n",
            "Epoch 25/50\n",
            "758/758 [==============================] - 0s 302us/step - loss: 1.3157 - accuracy: 0.3588 - val_loss: 1.2885 - val_accuracy: 0.3632\n",
            "Epoch 26/50\n",
            "758/758 [==============================] - 0s 311us/step - loss: 1.3154 - accuracy: 0.3747 - val_loss: 1.2872 - val_accuracy: 0.3842\n",
            "Epoch 27/50\n",
            "758/758 [==============================] - 0s 309us/step - loss: 1.3141 - accuracy: 0.3734 - val_loss: 1.2890 - val_accuracy: 0.3789\n",
            "Epoch 28/50\n",
            "758/758 [==============================] - 0s 300us/step - loss: 1.3136 - accuracy: 0.3575 - val_loss: 1.2866 - val_accuracy: 0.3895\n",
            "Epoch 29/50\n",
            "758/758 [==============================] - 0s 303us/step - loss: 1.3142 - accuracy: 0.3747 - val_loss: 1.2848 - val_accuracy: 0.3895\n",
            "Epoch 30/50\n",
            "758/758 [==============================] - 0s 308us/step - loss: 1.3125 - accuracy: 0.3654 - val_loss: 1.2882 - val_accuracy: 0.3895\n",
            "Epoch 31/50\n",
            "758/758 [==============================] - 0s 308us/step - loss: 1.3126 - accuracy: 0.3654 - val_loss: 1.2892 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "758/758 [==============================] - 0s 311us/step - loss: 1.3117 - accuracy: 0.3747 - val_loss: 1.2852 - val_accuracy: 0.3842\n",
            "Epoch 33/50\n",
            "758/758 [==============================] - 0s 304us/step - loss: 1.3124 - accuracy: 0.3826 - val_loss: 1.2804 - val_accuracy: 0.3789\n",
            "Epoch 34/50\n",
            "758/758 [==============================] - 0s 307us/step - loss: 1.3112 - accuracy: 0.3668 - val_loss: 1.2789 - val_accuracy: 0.3789\n",
            "Epoch 35/50\n",
            "758/758 [==============================] - 0s 331us/step - loss: 1.3115 - accuracy: 0.3522 - val_loss: 1.2851 - val_accuracy: 0.3947\n",
            "Epoch 36/50\n",
            "758/758 [==============================] - 0s 317us/step - loss: 1.3108 - accuracy: 0.4063 - val_loss: 1.2779 - val_accuracy: 0.3684\n",
            "Epoch 37/50\n",
            "758/758 [==============================] - 0s 312us/step - loss: 1.3106 - accuracy: 0.3734 - val_loss: 1.2862 - val_accuracy: 0.3947\n",
            "Epoch 38/50\n",
            "758/758 [==============================] - 0s 301us/step - loss: 1.3103 - accuracy: 0.3747 - val_loss: 1.2810 - val_accuracy: 0.3842\n",
            "Epoch 39/50\n",
            "758/758 [==============================] - 0s 332us/step - loss: 1.3090 - accuracy: 0.3641 - val_loss: 1.2846 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "758/758 [==============================] - 0s 313us/step - loss: 1.3095 - accuracy: 0.3879 - val_loss: 1.2889 - val_accuracy: 0.3842\n",
            "Epoch 41/50\n",
            "758/758 [==============================] - 0s 305us/step - loss: 1.3088 - accuracy: 0.3852 - val_loss: 1.2819 - val_accuracy: 0.3789\n",
            "Epoch 42/50\n",
            "758/758 [==============================] - 0s 307us/step - loss: 1.3079 - accuracy: 0.3826 - val_loss: 1.2832 - val_accuracy: 0.3789\n",
            "Epoch 43/50\n",
            "758/758 [==============================] - 0s 307us/step - loss: 1.3079 - accuracy: 0.3826 - val_loss: 1.2854 - val_accuracy: 0.3632\n",
            "Epoch 44/50\n",
            "758/758 [==============================] - 0s 317us/step - loss: 1.3070 - accuracy: 0.3813 - val_loss: 1.2835 - val_accuracy: 0.3947\n",
            "Epoch 45/50\n",
            "758/758 [==============================] - 0s 304us/step - loss: 1.3064 - accuracy: 0.3892 - val_loss: 1.2853 - val_accuracy: 0.3632\n",
            "Epoch 46/50\n",
            "758/758 [==============================] - 0s 302us/step - loss: 1.3066 - accuracy: 0.3799 - val_loss: 1.2802 - val_accuracy: 0.3842\n",
            "Epoch 47/50\n",
            "758/758 [==============================] - 0s 293us/step - loss: 1.3062 - accuracy: 0.3865 - val_loss: 1.2797 - val_accuracy: 0.3842\n",
            "Epoch 48/50\n",
            "758/758 [==============================] - 0s 311us/step - loss: 1.3065 - accuracy: 0.3694 - val_loss: 1.2860 - val_accuracy: 0.3895\n",
            "Epoch 49/50\n",
            "758/758 [==============================] - 0s 320us/step - loss: 1.3055 - accuracy: 0.3786 - val_loss: 1.2852 - val_accuracy: 0.3842\n",
            "Epoch 50/50\n",
            "758/758 [==============================] - 0s 304us/step - loss: 1.3046 - accuracy: 0.3813 - val_loss: 1.2760 - val_accuracy: 0.3947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYFofViu0y3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "92f3c8a5-aa96-4842-eb2a-5b6539481480"
      },
      "source": [
        "#evaluasi\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4564987e79cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#evaluasi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] evaluating network...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p19LN8OCS1EJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "ab38ea51-7012-4e8b-d2ca-54036c35bfc5"
      },
      "source": [
        "#evaluasi\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Grade A       0.28      0.11      0.16        46\n",
            "   Grade AA        0.40      0.35      0.37        48\n",
            "     Grade B       0.41      0.68      0.51        78\n",
            "    Grade C        0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.39       190\n",
            "   macro avg       0.27      0.29      0.26       190\n",
            "weighted avg       0.34      0.39      0.34       190\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPECmHxL04lh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6fbb03-44fa-4756-8bc9-a8d66cb2ed1a"
      },
      "source": [
        "#evaluasi 2\n",
        "test_score = model.evaluate(testX, testY, batch_size = 32)\n",
        "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "190/190 [==============================] - 0s 177us/step\n",
            "Test loss 1.2871, accuracy 38.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt20syQk07gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bikin grafik epoch sama Val_acc\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "epochs = H.epoch\n",
        "hist = pd.DataFrame(H.history)\n",
        "list_of_metrics_to_plot = ['val_acc']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2bSlTYf1CqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#grafik val_acc sama train_acc\n",
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots()\n",
        "ax.plot([None] + H.history['acc'], 'o-')\n",
        "ax.plot([None] + H.history['val_acc'], 'x-')\n",
        "# Plot legend and use the best location automatically: loc = 0.\n",
        "ax.legend(['Train acc', 'Validation acc'], loc = 0)\n",
        "ax.set_title('Training/Validation acc per Epoch')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9elumI_1E3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#grafik loss train dengan loss val\n",
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots()\n",
        "ax.plot([None] + H.history['loss'], 'o-')\n",
        "ax.plot([None] + H.history['val_loss'], 'x-')\n",
        "# Plot legend and use the best location automatically: loc = 0.\n",
        "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
        "ax.set_title('Training/Validation Loss per Epoch')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycCt5vjB1GqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bikin Confusion\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels=[\"Grade AA\", \"Grade A\", \"Grade B\",\"Grade C\"]\n",
        "print(confusion_matrix(testY, predY))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSQ0W2831IkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run \n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "cm=multilabel_confusion_matrix(testY,predY)\n",
        "print(cm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY9zxfa-1KiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "predY[1]\n",
        "rounded_labels=np.argmax(predY, axis=1)\n",
        "rounded_labels[1]\n",
        "rounded_predict=np.argmax(testY, axis=1)\n",
        "rounded_predict[1]\n",
        "print(confusion_matrix(rounded_labels, rounded_predict))\n",
        "rounded_labels[:,2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqrVjjUN1OnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11'],\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    if normalize:\n",
        "      plt.imshow(cm/7, interpolation='nearest', cmap=cmap)\n",
        "    else:\n",
        "      plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.3f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlUKcWVD1lLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run\n",
        "#gambar confusion matrix\n",
        "cm = confusion_matrix(rounded_labels,  rounded_predict)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a11JZncU1ojA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "#inputs = Input(shape=(224, 224, 3))\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "visualization_model = Model(inputs, successive_outputs, name = \"Lenet\")\n",
        "\n",
        "img = load_img('Dataset/Grade A/IMG_0507.jpg', target_size=(32, 32))\n",
        "\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Postprocess the feature to make it visually palatable\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}